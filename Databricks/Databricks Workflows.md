
- **Workflows** is a fully-managed cloud-based general-purpose task orchestration service for the entire [[Lakehouse]].
- **Workflows** is a service for data engineers, data scientists and analysts to build reliable data, analytics and Al workflows on any cloud.
- Databricks workflows enables all data teams to orchestrate any combination of tasks such as notebooks, SQL, ML Models and Python code.
- As workflows sit on the top of the Databricks platform, it can be fully integrated with other services
- With Databricks workflows, your team can easily create, run , monitor and repair data pipelines without managing any infrastructure.
- Databricks has two main task orchestration services
	- Workflow Jobs (Workflows)
		- workflows for every job
		- workflows is the service for orchestrating all types of tasks. in other words it can orchestrate any combination of notebooks,SQL, SPARK, ML Model and DLT(Delta Live Tables)
	- Delta Live Tables (DLT)
		- Automated data pipelines for Delta Lake
		- DLT are designed for data teams to easily create 

>DLT pipeline can be a task in a workflow

